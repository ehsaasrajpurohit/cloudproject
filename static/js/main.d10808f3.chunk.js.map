{"version":3,"sources":["Utilities.js","App.js","index.js"],"names":["fingerJoints","thumb","indexFinger","middleFinger","ringFinger","pinky","drawHand","predictions","ctx","length","forEach","prediction","landmarks","j","Object","keys","finger","k","firstJointIndex","secondJointIndex","beginPath","moveTo","lineTo","strokeStyle","lineWidth","stroke","i","x","y","arc","Math","PI","fillStyle","fill","App","webcamRef","useRef","canvasRef","runHandPose","a","handpose","net","console","log","setInterval","detect","current","video","readyState","videoWidth","videoHeight","width","height","estimateHands","hand","getContext","className","ref","style","position","marginLeft","marginRight","left","right","textAlign","zindex","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"yWACMA,G,OAAe,CACnBC,MAAO,CAAC,EAAG,EAAG,EAAG,EAAG,GACpBC,YAAa,CAAC,EAAG,EAAG,EAAG,EAAG,GAC1BC,aAAc,CAAC,EAAG,EAAG,GAAI,GAAI,IAC7BC,WAAY,CAAC,EAAG,GAAI,GAAI,GAAI,IAC5BC,MAAO,CAAC,EAAG,GAAI,GAAI,GAAI,MA4BZC,EAAW,SAACC,EAAaC,GAEhCD,EAAYE,OAAS,GACvBF,EAAYG,SAAQ,SAACC,GAMnB,IAHA,IAAMC,EAAYD,EAAWC,UAGpBC,EAAI,EAAGA,EAAIC,OAAOC,KAAKf,GAAcS,OAAQI,IAIpD,IAHA,IAAIG,EAASF,OAAOC,KAAKf,GAAca,GAG9BI,EAAI,EAAGA,EAAIjB,EAAagB,GAAQP,OAAS,EAAGQ,IAAK,CAGxD,IAAMC,EAAkBlB,EAAagB,GAAQC,GACvCE,EAAmBnB,EAAagB,GAAQC,EAAI,GAGlDT,EAAIY,YACJZ,EAAIa,OACFT,EAAUM,GAAiB,GAC3BN,EAAUM,GAAiB,IAE7BV,EAAIc,OACFV,EAAUO,GAAkB,GAC5BP,EAAUO,GAAkB,IAE9BX,EAAIe,YAAc,OAClBf,EAAIgB,UAAY,EAChBhB,EAAIiB,SAKR,IAAK,IAAIC,EAAI,EAAGA,EAAId,EAAUH,OAAQiB,IAAK,CACzC,IAAMC,EAAIf,EAAUc,GAAG,GACjBE,EAAIhB,EAAUc,GAAG,GAEvBlB,EAAIY,YACJZ,EAAIqB,IAAIF,EAAGC,EAAG,EAAG,EAAG,EAAIE,KAAKC,IAE7BvB,EAAIwB,UAAY,OAChBxB,EAAIyB,Y,QCcGC,MArFf,WACE,IAAMC,EAAYC,iBAAO,MACnBC,EAAYD,iBAAO,MAEnBE,EAAW,uCAAG,4BAAAC,EAAA,sEACAC,MADA,OACZC,EADY,OAElBC,QAAQC,IAAI,mBAGZC,aAAY,WACVC,EAAOJ,KACN,KAPe,2CAAH,qDAYXI,EAAM,uCAAG,WAAOJ,GAAP,uBAAAF,EAAA,yDAGkB,qBAAtBJ,EAAUW,SACK,OAAtBX,EAAUW,SAC6B,IAAvCX,EAAUW,QAAQC,MAAMC,WALb,wBAQLD,EAAQZ,EAAUW,QAAQC,MAC1BE,EAAaF,EAAME,WACnBC,EAAcH,EAAMG,YAG1Bf,EAAUW,QAAQC,MAAMI,MAAQF,EAChCd,EAAUW,QAAQC,MAAMK,OAASF,EAGjCb,EAAUS,QAAQK,MAAQF,EAC1BZ,EAAUS,QAAQM,OAASF,EAlBhB,UAqBQT,EAAIY,cAAcN,GArB1B,QAqBLO,EArBK,OAsBXZ,QAAQC,IAAIW,GAGN9C,EAAM6B,EAAUS,QAAQS,WAAW,MACzCjD,EAASgD,EAAM9C,GA1BJ,4CAAH,sDAgCZ,OAFA8B,IAGE,qBAAKkB,UAAU,MAAf,SACE,yBAAQA,UAAU,aAAlB,UACE,cAAC,IAAD,CACEC,IAAKtB,EACLuB,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EACRd,MAAO,IACPC,OAAQ,OAIZ,wBACEK,IAAKpB,EACLqB,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EACRd,MAAO,IACPC,OAAQ,aC/EpBc,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,W","file":"static/js/main.d10808f3.chunk.js","sourcesContent":["// Points for fingers\nconst fingerJoints = {\n  thumb: [0, 1, 2, 3, 4],\n  indexFinger: [0, 5, 6, 7, 8],\n  middleFinger: [0, 9, 10, 11, 12],\n  ringFinger: [0, 13, 14, 15, 16],\n  pinky: [0, 17, 18, 19, 20],\n};\n\n /*\n    `predictions` is basically an array of objects describing each detected hand, for example:\n    [\n      {\n        handInViewConfidence: 1, // The probability of a hand being present.\n        boundingBox: { // The bounding box surrounding the hand.\n          topLeft: [162.91, -17.42],\n          bottomRight: [548.56, 368.23],\n        },\n        landmarks: [ // The 3D coordinates of each hand landmark.\n          [472.52, 298.59, 0.00],\n          [412.80, 315.64, -6.18],\n          ...\n        ],\n        annotations: { // Semantic groupings of the `landmarks` coordinates.\n          thumb: [\n            [412.80, 315.64, -6.18]\n            [350.02, 298.38, -7.14],\n            ...\n          ],\n          ...\n        }\n      }\n    ]\n  */\nexport const drawHand = (predictions, ctx) => {\n  \n  if (predictions.length > 0) {\n    predictions.forEach((prediction) => {\n\n      // Grab landmarks\n      const landmarks = prediction.landmarks;\n\n      // Loop through fingers\n      for (let j = 0; j < Object.keys(fingerJoints).length; j++) {\n        let finger = Object.keys(fingerJoints)[j];\n\n        //  Loop through pairs of joints\n        for (let k = 0; k < fingerJoints[finger].length - 1; k++) {\n\n          // Get pairs of joints\n          const firstJointIndex = fingerJoints[finger][k];\n          const secondJointIndex = fingerJoints[finger][k + 1];\n\n          // Draw path\n          ctx.beginPath();\n          ctx.moveTo(\n            landmarks[firstJointIndex][0],\n            landmarks[firstJointIndex][1]\n          );\n          ctx.lineTo(\n            landmarks[secondJointIndex][0],\n            landmarks[secondJointIndex][1]\n          );\n          ctx.strokeStyle = \"plum\";\n          ctx.lineWidth = 4;\n          ctx.stroke();\n        }\n      }\n\n      // Loop through landmarks and draw\n      for (let i = 0; i < landmarks.length; i++) {\n        const x = landmarks[i][0];\n        const y = landmarks[i][1];\n        \n        ctx.beginPath();\n        ctx.arc(x, y, 6, 0, 3 * Math.PI);\n\n        ctx.fillStyle = \"gold\";\n        ctx.fill();\n      }\n    });\n  }\n};\n","import { useRef } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as handpose from \"@tensorflow-models/handpose\";\nimport Webcam from \"react-webcam\";\nimport './App.css';\nimport { drawHand } from \"./Utilities\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  const runHandPose = async () => {\n    const net = await handpose.load()\n    console.log(\"Loaded handpose\");\n\n    // Looping to detect hands \n    setInterval(() => {\n      detect(net)\n    }, 100);\n\n  }\n\n  // To detect a hand for handpose to run\n  const detect = async (net) => {\n    // Check data is available\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = video.videoWidth;\n      const videoHeight = video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas height and width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // Make Detections\n      const hand = await net.estimateHands(video);\n      console.log(hand);\n\n      // Draw mesh\n      const ctx = canvasRef.current.getContext(\"2d\");\n      drawHand(hand, ctx);\n    }\n  }\n\n  runHandPose();\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n"],"sourceRoot":""}